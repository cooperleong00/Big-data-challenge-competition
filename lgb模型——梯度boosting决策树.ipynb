{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17000it [00:00, 1420381.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "[ 82 310   9 280 188 224 215 236 176   0   0   0 248 367 357 339 216 336\n",
      " 367 381  32 190 330 308 332 206 309 222 279 221 367 372 260   0   0   0\n",
      " 301 344 413]\n",
      "<lightgbm.basic.Booster object at 0x000002589D1DD400>\n",
      "{'auc-mean': [0.597173135814497, 0.5999724964109644, 0.6032045710615601, 0.6049845426326261, 0.6066458832182299, 0.6080440507674544, 0.6086268569578404, 0.6088390205028582, 0.6102357954357108, 0.6107708835522598, 0.6103189737545087, 0.6102741194796231, 0.6106153310183962, 0.6113693457326643, 0.6110858450079879, 0.6114632302464094, 0.6112045656407605, 0.6118601675491917, 0.611849862219033, 0.6121526189903045, 0.6121497219056, 0.613010648926285], 'auc-stdv': [0.01412746081991307, 0.014378770505077444, 0.016061263969761364, 0.01566860077485317, 0.016536656044956837, 0.01669950691622316, 0.016871075630739085, 0.01693666458360434, 0.016575000783407928, 0.01595811892153831, 0.016044025180514728, 0.016797116105017922, 0.015876300438424595, 0.015684760426596164, 0.01608553023590425, 0.016367416666501013, 0.01592541911438853, 0.015728171853914376, 0.016036117817628506, 0.015849992350163503, 0.0156772658816376, 0.015781240939808896]}\n",
      "Training lgb model, using time：1.9587600231170654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#创建lgb模型    API:https://lightgbm.readthedocs.io/en/latest/Python-API.html\n",
    "#参数说明：传入总特征文件，传入标签文件和输出文件名\n",
    "def make_lgb_model(train_file,label_file,outfile):\n",
    "    #参数列表\n",
    "    params = {'boosting_type': 'gbdt',\n",
    "                  'objective': 'binary',\n",
    "                  'metric': ['auc','binary_loss'], \n",
    "                  'num_leaves': 31,\n",
    "                  'max_depth' : 7,\n",
    "                  'learning_rate': 0.1,\n",
    "                  'feature_fraction': 1.0,\n",
    "                  #'bagging_fraction': 0.9,\n",
    "                  #'bagging_seed': 0,\n",
    "                  #'bagging_freq': 1,\n",
    "                  #'seed':1024,\n",
    "                  #'verbosity':10,\n",
    "                  #'first_metric_only':True\n",
    "                  #'lambda_l1': 0,\n",
    "                  #'lambda_l2': 0,\n",
    "                  #'ignore_column': [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]\n",
    "                  #'ignore_column':[5,6,12,16,22,27,28] \n",
    "    }\n",
    "    lb=[]\n",
    "    with open(label_file,'r') as lb_file:\n",
    "        lb_reader = csv.reader(lb_file, delimiter=',')\n",
    "        for row in tqdm(lb_reader,mininterval=1.0):\n",
    "            lb.append(int(row[0]))\n",
    "        #创建lgb所需的训练数据集,weight为权重（与attention机制相对应）\n",
    "        train_data = lgb.Dataset(train_file,lb,weight=None)\n",
    "    start = time.time()\n",
    "    #进行训练,num_boost_round为训练轮数\n",
    "    bst = lgb.train(params, train_data, num_boost_round = 300)\n",
    "    #输出特征数\n",
    "    print(bst.num_feature())\n",
    "    #输出特征重要性\n",
    "    print(bst.feature_importance())\n",
    "    #保存lgb模型\n",
    "    bst.save_model(outfile)\n",
    "    print(bst)\n",
    "    #进行交叉验证，nfold为交叉准备集数量，10个集合， 100轮,early_stopping_rounds为早停轮，如果5轮没能改进成绩就不再训练\n",
    "    bst_valid = lgb.cv(params, train_data,nfold=10,num_boost_round=300,early_stopping_rounds=5)\n",
    "    #显示分数\n",
    "    print(bst_valid)\n",
    "    \n",
    "    print('Training lgb model, using time：'+str(time.time()-start))\n",
    "    return True\n",
    "\n",
    "#调用该函数\n",
    "make_lgb_model('all_feature_train.txt','lb_train.txt','lgb_model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 444/444 [00:00<00:00, 1193.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5134933418345764"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#检测Qauc的程序，思路：把query_id相同的部分集群，然后计算其roc_auc_score，然后取所有的平均值\n",
    "#输入result（一位数组），真实表文件（包括两个id和正确的标签），将输出qauc值\n",
    "def metric_auc(predict,file ,start, end):\n",
    "    start_time = time.time()\n",
    "    #总数量较小，可以使用pandas\n",
    "    true = pd.read_csv('test.csv',header=None)\n",
    "\n",
    "    '''\n",
    "    true:      DataFrame , ['query_id','query_title_id','label']\n",
    "    predict:   np.array , [0.79,0.03,0.56,...]\n",
    "    '''\n",
    "    #拼接\n",
    "    true = pd.concat([true.reset_index(drop=True),pd.DataFrame(predict)],axis=1)\n",
    "    true.columns = ['query_id','query_title_id','label','predict']\n",
    "    auc_score = []\n",
    "    count = 0\n",
    "    #对query_id相同的进行集群\n",
    "    for i in tqdm(true.groupby('query_id'),mininterval=1.0):\n",
    "        a = i[1]\n",
    "        x = np.array(a['label'])\n",
    "        y = np.array(a['predict'])\n",
    "        #当一个query_id中所有标签都为0时会报错，所以添置为0.5\n",
    "        try:\n",
    "            auc_score.append(roc_auc_score(x,y))\n",
    "        except:\n",
    "            auc_score.append(0.5)  \n",
    "            count+=1\n",
    "    print(count)\n",
    "    return np.mean(auc_score)\n",
    "\n",
    "\n",
    "#读取lgb模型\n",
    "bst = lgb.Booster(model_file='lgb_model.txt')\n",
    "#预测\n",
    "predict = (bst.predict('all_feature_test.txt'))\n",
    "print(len(predict))\n",
    "metric_auc(predict,'test.csv',17000,20000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete, using time:0.007083892822265625\n"
     ]
    }
   ],
   "source": [
    "#作答环节\n",
    "#读取存储的lgb模型，传入测试集csv和测试集特征并且预测结果，保存到文件中\n",
    "def predict(lgb_model,feature_file,test_file,out_file):\n",
    "    #读取 \n",
    "    bst = lgb.Booster(model_file=lgb_model)\n",
    "    #预测\n",
    "    result = bst.predict(feature_file)\n",
    "    #newline=''防止写csv时每两行数据中空一行\n",
    "    with open(out_file, 'w',newline = '') as output:\n",
    "        with open(test_file) as csv_file:\n",
    "            #处理开始时间\n",
    "            start_time = time.time()\n",
    "            #打开csv_reader以及csv_writer\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            writer = csv.writer(output)\n",
    "            \n",
    "            line_count = 0\n",
    "            for row in csv_reader:\n",
    "                query_id = row[0]\n",
    "                title_id = row[2]\n",
    "                pred = result[line_count]\n",
    "                #写下csv一行\n",
    "                writer.writerow([query_id,title_id,pred])\n",
    "                line_count+=1\n",
    "    print(\"complete, \"+\"using time:\"+str(time.time()-start_time))\n",
    "\n",
    "        \n",
    "#调用该函数\n",
    "predict('lgb_model.txt','all_feature_test.txt','test.csv','result.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
