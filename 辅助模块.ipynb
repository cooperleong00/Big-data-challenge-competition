{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入各种包\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入需要的列：(逗号分隔)0,2,4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:00, 466220.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make text from train.csv using time 0.04484200477600098 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#语料生成模块,输入参数：读取的csv，输出的文件名，start为开始条数，end为结束条数，need_all为True则读取所有数据，否则读取指定数据\n",
    "#注：0为query_id,1为query,2为title_id,3为title,4为label。\n",
    "#已经做了优化，内存占用极低，效率很高（pandas内存占用较大，没有采用）\n",
    "def make_csv_from_csv(filename,outputfile,start,end,need_all):\n",
    "    with open(outputfile, 'w',newline = '') as output:\n",
    "        with open(filename) as csv_file:\n",
    "            #处理开始时间\n",
    "            start_time = time.time()\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            #python内置csv.writer\n",
    "            writer = csv.writer(output)\n",
    "            i = 0\n",
    "            if need_all==True:\n",
    "                for row in tqdm(csv_reader,mininterval=1.0):\n",
    "                    if (i >=start and i<end):\n",
    "                        writer.writerow(row)\n",
    "                    i+=1\n",
    "            else:\n",
    "                ttype = input('输入需要的列：(逗号分隔)')\n",
    "                start_time = time.time()\n",
    "                ttype_list = list(map(int,ttype.split(',')))\n",
    "                for row in tqdm(csv_reader,mininterval=1.0):\n",
    "                    if (i >=start and i<end):\n",
    "                        line = []\n",
    "                        for j in ttype_list:\n",
    "                            line.append(row[j])\n",
    "                        writer.writerow(line)\n",
    "                    i+=1\n",
    "                        \n",
    "                    \n",
    "                    \n",
    "            \n",
    "            print(\"make text from \"+filename+\" using time \"+str(time.time()-start_time)+\" seconds\")\n",
    "    return True\n",
    "\n",
    "#调用该函数\n",
    "make_csv_from_csv('train.csv','test.csv',start = 17000,end = 20000, need_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:00, 142991.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make text from train.csv using time 0.1453719139099121 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#语料生成模块,输入参数：读取的csv，输出的文件名，ttype为指定输出。0为query_id,1为query,2为title_id,3为title,4为label。\n",
    "#已经做了优化，内存占用极低，效率很高\n",
    "def make_text_from_csv(filename,outputfile,ttype):\n",
    "    with open(outputfile, 'w') as output:\n",
    "        with open(filename) as csv_file:\n",
    "            #处理开始时间\n",
    "            start_time = time.time()\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            for row in tqdm(csv_reader,mininterval=1.0):\n",
    "                need = row[ttype]\n",
    "                output.write(\"{0}\\n\".format(need))\n",
    "                \n",
    "            print(\"make text from \"+filename+\" using time \"+str(time.time()-start_time)+\" seconds\")\n",
    "    return True\n",
    "#调用该函数\n",
    "make_text_from_csv('train.csv','title.txt',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:00, 156489.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make corpus from train.csv with 0lines, using time 0.1442575454711914 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [00:00, 155949.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make corpus from test.csv with 0lines, using time 0.023122549057006836 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将train.csv与test.csv的所有内容写到一个txt文件中\n",
    "def make_txt_from_2csv(outputfile):\n",
    "    with open(outputfile, 'w') as output:\n",
    "        #写train.csv\n",
    "        with open(\"train.csv\") as csv_file:\n",
    "            #处理开始时间\n",
    "            start_time = time.time()\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            line_count = 0\n",
    "            for row in tqdm(csv_reader,mininterval=1.0):\n",
    "                query_id = row[0]\n",
    "                query = row[1]\n",
    "                title_id = row[2]\n",
    "                title = row[3]\n",
    "                label = row[4]\n",
    "                output.write(\"{0},{1},{2},{3}\\n\".format(query_id,query,title_id, title,label))\n",
    "        print(\"make corpus from train.csv, using time \"+str(time.time()-start_time)+\" seconds\")\n",
    "        \n",
    "        #写test.csv\n",
    "        with open(\"test.csv\") as csv_file:\n",
    "            #处理开始时间\n",
    "            start_time = time.time()\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            for row in tqdm(csv_reader,mininterval=1.0):\n",
    "                query_id = row[0]\n",
    "                query = row[1]\n",
    "                title_id = row[2]\n",
    "                title = row[3]\n",
    "                label = row[4]\n",
    "                output.write(\"{0},{1},{2},{3}\\n\".format(query_id,query,title_id, title,label))\n",
    "        print(\"make corpus from test.csv, using time \"+str(time.time()-start_time)+\" seconds\")\n",
    "    return True\n",
    "\n",
    "#调用该函数\n",
    "make_txt_from_2csv('a.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 20000/20000 [00:00<00:00, 257095.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " using time 0.08179426193237305 seconds\n"
     ]
    }
   ],
   "source": [
    "#文本组合模块，输入一个txt文件的列表（四个），传入总长度，输出一个合成的文件\n",
    "#已经做了优化，内存占用极低，效率很高\n",
    "def text_conbine(feature_file_list,outputfile,length):\n",
    "    with open(outputfile,'w+') as output:\n",
    "        #处理开始时间\n",
    "        start_time = time.time()\n",
    "        with open(feature_file_list[0],'r') as f0:\n",
    "            with open(feature_file_list[1],'r') as f1:\n",
    "                with open(feature_file_list[2],'r') as f2:\n",
    "                    with open(feature_file_list[3],'r') as f3:\n",
    "                        #tqdm可以提供进度条，监控总长度变化\n",
    "                        for i in tqdm(range(length),mininterval=1.0):\n",
    "                            #读取一行数据，并且去除换行符\n",
    "                            line = f0.readline().strip('\\n') + ','+ f1.readline().strip('\\n')+ ','+ f2.readline().strip('\\n')+ ','+ f3.readline().strip('\\n')\n",
    "                            output.write(\"{0}\\n\".format(line))      \n",
    "\n",
    "                    \n",
    "            print(\" using time \"+str(time.time()-start_time)+\" seconds\")\n",
    "    return True\n",
    "\n",
    "#调用该函数\n",
    "text_conbine(['query_repeat.txt','title_repeat.txt','train_len_feature','tfidf_common_feature.txt'],'peter_feature.txt',length=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 20000/20000 [00:00<00:00, 174556.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " using time 0.12152719497680664 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#文本组合模块，输入一个txt文件的列表（两个），传入总长度，输出一个合成的文件\n",
    "#已经做了优化，内存占用极低，效率很高\n",
    "def feature_conbine(feature_file_list,outputfile,length):\n",
    "    with open(outputfile,'w+') as output:\n",
    "        #处理开始时间\n",
    "        start_time = time.time()\n",
    "        with open(feature_file_list[0],'r') as f0:\n",
    "            with open(feature_file_list[1],'r') as f1:\n",
    "            #tqdm可以提供进度条，监控总长度变化\n",
    "                for i in tqdm(range(length),mininterval=1.0):\n",
    "                    #读取一行数据，并且去除换行符\n",
    "                    line = f0.readline().strip('\\n') + ' '+ f1.readline().strip('\\n')\n",
    "                    output.write(\"{0}\\n\".format(line))      \n",
    "\n",
    "                    \n",
    "            print(\" using time \"+str(time.time()-start_time)+\" seconds\")\n",
    "    return True\n",
    "\n",
    "#调用该函数\n",
    "feature_conbine(['query.txt','title.txt'],'query_title.txt',length=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#文本组合模块，输入一个txt文件的列表（十一个），传入总长度，输出一个合成的文件\n",
    "#已经做了优化，内存占用极低，效率很高\n",
    "def feature_conbine(feature_file_list,outputfile,length):\n",
    "    with open(outputfile,'w+') as output:\n",
    "        #处理开始时间\n",
    "        start_time = time.time()\n",
    "        with open(feature_file_list[0],'r') as f0:\n",
    "            with open(feature_file_list[1],'r') as f1:\n",
    "                with open(feature_file_list[2],'r') as f2:\n",
    "                    with open(feature_file_list[3],'r') as f3:\n",
    "                        with open(feature_file_list[4],'r') as f4:\n",
    "                            with open(feature_file_list[5],'r') as f5:\n",
    "                                with open(feature_file_list[6],'r') as f6:\n",
    "                                    with open(feature_file_list[7],'r') as f7:\n",
    "                                        with open(feature_file_list[8],'r') as f8:\n",
    "                                            with open(feature_file_list[9],'r') as f9:\n",
    "                                                with open(feature_file_list[10],'r') as f10:\n",
    "            #tqdm可以提供进度条，监控总长度变化\n",
    "                                                    for i in tqdm(range(length),mininterval=1.0):\n",
    "                                                        #读取一行数据，并且去除换行符\n",
    "                                                        line = f0.readline().strip('\\n') + ','+ f1.readline().strip('\\n')+ ','+ f2.readline().strip('\\n')\\\n",
    "                                                            + ','+ f3.readline().strip('\\n')+ ','+ f4.readline().strip('\\n')+ ','+ f5.readline().strip('\\n')\\\n",
    "                                                            +','+ f6.readline().strip('\\n')+','+ f7.readline().strip('\\n')+','+ f8.readline().strip('\\n')\\\n",
    "                                                            +','+ f9.readline().strip('\\n')+','+ f10.readline().strip('\\n')\n",
    "                                                        output.write(\"{0}\\n\".format(line))      \n",
    "\n",
    "                    \n",
    "            print(\" using time \"+str(time.time()-start_time)+\" seconds\")\n",
    "    return True\n",
    "\n",
    "#调用该函数\n",
    "feature_conbine(['train_dis.txt','train_len_feature.txt','train_query_title_dis_v2.txt','train_tfidf_LR.txt','train_tfidf_mh.txt','train_w2v_sim_mat_mean.txt','query_repeat.txt','title_repeat.txt','query_repeat.txt','train_dis_v2.txt','train_query_title_dis_v2.txt','tfidf_common_feature.txt'],'feature_5.0.txt',length=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 20000/20000 [00:00<00:00, 85874.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " using time 0.24786138534545898 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#文本组合模块，输入一个txt文件的列表（十个），传入总长度，输出一个合成的文件\n",
    "#已经做了优化，内存占用极低，效率很高\n",
    "def feature_conbine(feature_file_list,outputfile,length):\n",
    "    with open(outputfile,'w+') as output:\n",
    "        #处理开始时间\n",
    "        start_time = time.time()\n",
    "        with open(feature_file_list[0],'r') as f0:\n",
    "            with open(feature_file_list[1],'r') as f1:\n",
    "                with open(feature_file_list[2],'r') as f2:\n",
    "                    with open(feature_file_list[3],'r') as f3:\n",
    "                        with open(feature_file_list[4],'r') as f4:\n",
    "                            with open(feature_file_list[5],'r') as f5:\n",
    "                                with open(feature_file_list[6],'r') as f6:\n",
    "                                    with open(feature_file_list[7],'r') as f7:\n",
    "                                        with open(feature_file_list[8],'r') as f8:\n",
    "                                            with open(feature_file_list[9],'r') as f9:\n",
    "                                                #tqdm可以提供进度条，监控总长度变化\n",
    "                                                for i in tqdm(range(length),mininterval=1.0):\n",
    "                                                    #读取一行数据，并且去除换行符\n",
    "                                                    line = f0.readline().strip('\\n') + ','+ f1.readline().strip('\\n')+ ','+ f2.readline().strip('\\n')\\\n",
    "                                                        + ','+ f3.readline().strip('\\n')+ ','+ f4.readline().strip('\\n')+ ','+ f5.readline().strip('\\n')\\\n",
    "                                                        +','+ f6.readline().strip('\\n')+','+ f7.readline().strip('\\n')+','+ f8.readline().strip('\\n')\\\n",
    "                                                        +','+ f9.readline().strip('\\n')\n",
    "                                                    output.write(\"{0}\\n\".format(line))      \n",
    "\n",
    "                    \n",
    "            print(\" using time \"+str(time.time()-start_time)+\" seconds\")\n",
    "    return True\n",
    "\n",
    "#调用该函数\n",
    "feature_conbine(['len_feature.txt','query_repeat.txt','query_title_dis.txt','tfidf_common_feature.txt','tfidf_LR.txt',\n",
    "                 'tfidf_MH.txt','title_repeat.txt','title_tfidf_common_feature.txt','w2v_d2v_distance.txt','w2v_sim_mat_mean.txt'],'all_feature.txt',length=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-58e14f37800b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m#调用该函数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lgb_model.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'features_v3.2.2.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'test.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'result.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-58e14f37800b>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(lgb_model, feature_file, test_file, out_file)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#newline=''防止写csv时每两行数据中空一行\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnewline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[1;31m#处理开始时间\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test.csv'"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "#读取存储的lgb模型，传入测试集csv和测试集总特征并且预测结果，保存到文件中\n",
    "def predict(lgb_model,feature_file,test_file,out_file):\n",
    "    #读取 \n",
    "    bst = lgb.Booster(model_file=lgb_model)\n",
    "    #预测\n",
    "    result = bst.predict(feature_file)\n",
    "    #newline=''防止写csv时每两行数据中空一行\n",
    "    with open(out_file, 'w',newline = '') as output:\n",
    "        with open(test_file) as csv_file:\n",
    "            #处理开始时间\n",
    "            start_time = time.time()\n",
    "            #打开csv_reader以及csv_writer\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            writer = csv.writer(output)\n",
    "            \n",
    "            line_count = 0\n",
    "            for row in csv_reader:\n",
    "                query_id = row[0]\n",
    "                title_id = row[2]\n",
    "                pred = result[line_count]\n",
    "                #写下csv一行\n",
    "                writer.writerow([query_id,title_id,pred])\n",
    "                line_count+=1\n",
    "    print(\"complete, \"+\"using time:\"+str(time.time()-start_time))\n",
    "\n",
    "        \n",
    "#调用该函数\n",
    "predict('lgb_model.txt','features_v3.2.2.txt','test.csv','result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 17000/17000 [00:00<00:00, 629964.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make text from lb.txt using time 0.028925418853759766 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#语料生成模块,输入参数：读取的txt，输出的文件名，开始和结束位置\n",
    "#已经做了优化，内存占用极低，效率很高\n",
    "#从txt中截取需要的行（所有内容）\n",
    "def make_text_from_text(filename,outputfile,begin,end):\n",
    "    with open(outputfile, 'w',newline = '') as output:\n",
    "        with open(filename) as f:\n",
    "            #处理开始时间\n",
    "            start_time = time.time()\n",
    "            for i in tqdm(range(end),mininterval=1.0):\n",
    "                if i <begin:\n",
    "                    f.readline().strip('\\n')\n",
    "                    continue\n",
    "                if i >= end:\n",
    "                    break\n",
    "                need = f.readline().strip('\\n')\n",
    "                #print(need)\n",
    "                output.write(\"{0}\\n\".format(need))\n",
    "                #print(i)\n",
    "            print(\"make text from \"+filename+\" using time \"+str(time.time()-start_time)+\" seconds\")\n",
    "            \n",
    "    return True\n",
    "\n",
    "#调用该函数\n",
    "make_text_from_text('lb.txt','lb_train.txt', begin=0, end=17000, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入需要删除的位数：(逗号分隔)0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 20000/20000 [00:00<00:00, 312796.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete, using time 1.042250156402588 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#删除text中的指定内容（对每一行进行删除）,运行后用户输入为几，就删除掉几的内容（从0开始）\n",
    "#已经优化，占用内存极低\n",
    "def del_text_from_text(filename,outputfile,length):\n",
    "    start_time = time.time()\n",
    "    ttype = input('输入需要删除的位数：(逗号分隔)')\n",
    "    ttype_list = list(map(int,ttype.split(',')))\n",
    "    #倒序\n",
    "    ttype_list.sort(reverse=True)\n",
    "    \n",
    "    with open(outputfile, 'w') as output:\n",
    "        with open(filename,'r') as f:\n",
    "            for i in tqdm(range(length),mininterval=1.0):\n",
    "                lst = f.readline().strip('\\n').split(',')\n",
    "                \n",
    "                for j in ttype_list:\n",
    "                    del lst[j]\n",
    "                s = ','.join(lst)\n",
    "                output.write(\"{0}\\n\".format(s))\n",
    "    print(\"complete, using time \"+str(time.time()-start_time)+\" seconds\")\n",
    "    return True\n",
    "\n",
    "#调用该函数\n",
    "del_text_from_text('lb.txt','test.txt',length = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "压缩文件：query.txt， using time 0.018685579299926758 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#压缩指定txt，生成txt.gz文件（减少空间占用）（内容变为二进制文件）\n",
    "def compress_feature(filename):\n",
    "    #处理开始时间\n",
    "    start_time = time.time()\n",
    "    #打开被压缩文件，打开压缩文件（没有则创建）\n",
    "    with open(filename,'rb') as ff,gzip.open(filename+'.gz','wb') as cf:\n",
    "        #使用了复制模式，速度很快\n",
    "        shutil.copyfileobj(ff, cf)\n",
    "    \n",
    "    print(\"压缩文件：\"+filename+\"， using time \"+str(time.time()-start_time)+\" seconds\")        \n",
    "    return True\n",
    "\n",
    "#调用该函数\n",
    "compress_feature('query.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 20000/20000 [00:00<00:00, 823785.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using time 0.05173969268798828 seconds\n",
      "['1427 5661 29788 1427 387 2299 372 22 1586 1025 218 165 218 27 7092 22 266 25817 4550 2136 11 60847 9156 1077 797 27 689 3447 11146 108 1667 46829 161702 1113017 548478 24274 5062 46829', '1427 5661 29788 1427 387 2299 372 22 1586 1025 218 165 218 27 7092 22 266 25817 4550 2136 11 60847 9156 1077 797 27 689 3447 11146 108 1667 46829 161702 1113017 548478 24274 5062 46829']\n"
     ]
    }
   ],
   "source": [
    "#从txt.gz压缩文件中读取所有数据，返回一个含有所有数据的list\n",
    "def load_list_from_cpfile(cpfile,length):\n",
    "    with gzip.open(cpfile, 'rb') as cpfile:\n",
    "        start_time = time.time()\n",
    "        file_content = cpfile.readlines()\n",
    "        result = []\n",
    "        for i in tqdm(range(length),mininterval=1.0):\n",
    "            #编码为二进制，返回为十进制，并去掉\\t\\r\\n这些限定符\n",
    "            need = file_content[i].decode().strip('\\t\\r\\n')\n",
    "            result.append(need)\n",
    "            \n",
    "    print(\"using time \"+str(time.time()-start_time)+\" seconds\")        \n",
    "    return result\n",
    "    \n",
    "a = load_list_from_cpfile('query.txt.gz',20000)\n",
    "#展现前两个\n",
    "print(a[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.25170819259181193', '0.2957471845505276', '0.06377310615759955', '0.0033096524488300002', '3.775622888877179', '0.2672547794653493']\n",
      "['0.2573372917796861', '0.3457951561114256', '0.1283356866190581', '0.00520608968806812', '3.6027220849156056', '0.28216545286146155']\n",
      "长度：6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看txt文件的前两行，观察是否正常\n",
    "#用户可以指定分隔符，以应对不同分隔符的文件\n",
    "def test_txt(file,separation_character = ','):\n",
    "    with open(file, 'r') as f:\n",
    "        line1 = f.readline().strip('\\n').split(separation_character)\n",
    "        line2 = f.readline().strip('\\n').split(separation_character)\n",
    "        print(line1)\n",
    "        print(line2)\n",
    "        print('长度：'+str(len(line1)))\n",
    "    return True\n",
    "\n",
    "#调用该函数\n",
    "test_txt('title_tfidf_common_feature.txt',separation_character=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text读出csv，传入text.txt，传出同样内容的csv文件\n",
    "def text_to_csv(file,out_file,length = 1000000):\n",
    "    #newline=''防止写csv时每两行数据中空一行\n",
    "    with open(out_file, 'w',newline = '') as output:\n",
    "        with open(file) as f:\n",
    "            #处理开始时间\n",
    "            start_time = time.time()\n",
    "            #打开csv_reader以及csv_writer\n",
    "            writer = csv.writer(output)\n",
    "            \n",
    "            for i in tqdm(range(length),mininterval=1.0):\n",
    "                line = f.readline().strip('\\n\\t')\n",
    "                line = line.split(',')\n",
    "                #写下csv一行\n",
    "                writer.writerow([line[0],line[1],line[2]])\n",
    "    print(\"complete, \"+\"using time:\"+str(time.time()-start_time))\n",
    "\n",
    "text_to_csv('qauc_true.txt','qauc_true.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:00, 226591.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max 300,35 min 1,1 avg 4.026250000000656,13.699550000000146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#获得train.csv中的query和title长度以及它们的平均值，对后面模型的建立有指导作用\n",
    "def evaluate_len(data_file,length):\n",
    "    with open(data_file) as train_data:\n",
    "        train_reader = csv.reader(train_data, delimiter=',')\n",
    "        query_id_set = set()\n",
    "        query_info=[0,10000,0]#max,min,avg\n",
    "        title_info=[0,10000,0]\n",
    "        #流式算法，如果有比最大值大的，取代原最大值，最小值同理\n",
    "        for row in tqdm(train_reader):\n",
    "            if len(row[1].split(' '))>query_info[0]:\n",
    "                query_info[0] = len(row[1].split(' '))\n",
    "            if len(row[3].split(' '))>title_info[0]:\n",
    "                title_info[0] = len(row[3].split(' '))\n",
    "            if len(row[1].split(' '))<query_info[1]:\n",
    "                query_info[1] = len(row[1].split(' '))\n",
    "            if len(row[3].split(' '))<title_info[1]:\n",
    "                title_info[1] = len(row[3].split(' '))\n",
    "            #平均值的计算（先除再加）\n",
    "            query_info[2] += len(row[1].split(' '))/length\n",
    "            title_info[2] += len(row[3].split(' '))/length\n",
    "        print('max '+str(query_info[0])+\",\"+str(title_info[0])+' min '+str(query_info[1])+\",\"+str(title_info[1])+' avg '+str(query_info[2])+\",\"+str(title_info[2]))\n",
    "    return True\n",
    "\n",
    "#调用该函数\n",
    "evaluate_len('train.csv',20000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
